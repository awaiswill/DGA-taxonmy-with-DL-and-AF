{
 "cells": [],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "# Load Libraries\n",
     "import warnings\n",
     "from datetime import datetime\n",
     "\n",
     "import tensorflow as tf\n",
     "from keras.utils.generic_utils import get_custom_objects\n",
     "from keras.layers import Activation\n",
     "from keras import backend as K\n",
     "from keras import regularizers\n",
     "from keras.callbacks import EarlyStopping\n",
     "from keras.callbacks import ModelCheckpoint\n",
     "from keras.layers import Bidirectional, LSTM\n",
     "from keras.layers import Input, ELU, Embedding, BatchNormalization, Convolution1D, MaxPooling1D, concatenate\n",
     "from keras.layers.core import Dense, Dropout, Flatten\n",
     "from keras.models import Model\n",
     "from keras.optimizers import Adam\n",
     "from keras_self_attention import SeqSelfAttention\n",
     "from model_evaluator import Evaluator\n",
     "from model_preprocessor import Preprocessor\n",
     "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
     "import math\n",
     "from activation_functions import swish\n",
     "# import tensorflow.compat.v1 as tf\n",
     "# tf.disable_v2_behavior()\n",
     "\n",
     "# warnings.filterwarnings(\"ignore\")\n",
     "# config = tf.ConfigProto()\n",
     "# config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
     "# tf.compat.v1.keras.backend.set_session(tf.Session(config=config))\n",
     "\n",
     "warnings.filterwarnings(\"ignore\")\n",
     "config = tf.compat.v1.ConfigProto()\n",
     "config.allow_soft_placement = True\n",
     "# config.log_device_placement = True\n",
     "config.gpu_options.allow_growth = True\n",
     "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
     "K.tensorflow_backend.set_session(tf.compat.v1.Session(config=config))\n",
     "\n",
     "get_custom_objects().update({'swish': Activation(swish)})\n",
     "\n",
     "with tf.device(\"/GPU:0\"):\n",
     "\n",
     "    def get_conv_layer(emb, kernel_size=5, filters=256):\n",
     "        # Conv layer\n",
     "        conv = Convolution1D(kernel_size=kernel_size, filters=filters)(emb)\n",
     "        conv = ELU()(conv)\n",
     "        conv = MaxPooling1D(5)(conv)\n",
     "        conv = Dropout(0.5)(conv)\n",
     "        return conv\n",
     "\n",
     "    def cnn_bilstm_att(max_len=73, emb_dim=32, max_vocab_len=39, W_reg=regularizers.l2(1e-4)):\n",
     "        # Input\n",
     "        main_input = Input(shape=(max_len,), dtype='int32', name='main_input')\n",
     "\n",
     "        # Embedding layer\n",
     "        # emb = Embedding(input_dim=max_vocab_len, output_dim=emb_dim, input_length=max_len, embeddings_regularizer=W_reg)(main_input)\n",
     "        emb = Embedding(input_dim=max_vocab_len, output_dim=emb_dim, input_length=max_len, W_regularizer=W_reg)(main_input)\n",
     "        emb = Dropout(0.2)(emb)\n",
     "\n",
     "        conv2 = get_conv_layer(emb, kernel_size=2, filters=256)\n",
     "        conv3 = get_conv_layer(emb, kernel_size=3, filters=256)\n",
     "        conv4 = get_conv_layer(emb, kernel_size=4, filters=256)\n",
     "        conv5 = get_conv_layer(emb, kernel_size=5, filters=256)\n",
     "\n",
     "        bilstm = Bidirectional(LSTM(units=128, return_sequences=True, dropout=0.2, activation=swish))(emb)\n",
     "\n",
     "        att = SeqSelfAttention()(bilstm)\n",
     "\n",
     "        cnnlstm_merged = concatenate([conv2, conv3, conv4, conv5, att], axis=1)\n",
     "        cnnlstm_merged = Flatten()(cnnlstm_merged)\n",
     "\n",
     "        hidden1 = Dense(4128)(cnnlstm_merged)\n",
     "        hidden1 = ELU()(hidden1)\n",
     "        hidden1 = BatchNormalization(mode=0)(hidden1)\n",
     "        hidden1 = Dropout(0.5)(hidden1)\n",
     "\n",
     "        hidden2 = Dense(1024)(hidden1)\n",
     "        hidden2 = ELU()(hidden2)\n",
     "        hidden2 = BatchNormalization(mode=0)(hidden2)\n",
     "        hidden2 = Dropout(0.5)(hidden2)\n",
     "\n",
     "        # Output layer (last fully connected layer)\n",
     "        output = Dense(21, activation='softmax', name='output')(hidden2)\n",
     "\n",
     "        # Compile model and define optimizer\n",
     "        model = Model(input=[main_input], output=[output])\n",
     "        return model\n",
     "\n",
     "\n",
     "with tf.device(\"/GPU:0\"):\n",
     "\n",
     "    # Load data using model preprocessor\n",
     "    x_train, x_test, y_train, y_test = Preprocessor.load_data()\n",
     "\n",
     "    # Define Deep Learning Model\n",
     "    model_name = \"ENSEMBLE_CNN_BILSTM\"\n",
     "    model = cnn_bilstm_att()\n",
     "    model.summary()\n",
     "    # Define early stopping\n",
     "    mc = ModelCheckpoint(filepath='./trained_models/' + model_name+ '.hdf5', monitor='val_loss', mode='min',\n",
     "                         save_best_only=True, verbose=1)\n",
     "\n",
     "    ''' Training phrase '''\n",
     "    epochs = 10\n",
     "    batch_size = 64\n",
     "    adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
     "\n",
     "    model.compile(optimizer=adam, loss='categorical_crossentropy',\n",
     "                  metrics=['accuracy', tf.keras.metrics.CategoricalAccuracy(),\n",
     "                           Evaluator.precision, Evaluator.recall, Evaluator.fmeasure])\n",
     "\n",
     "    dt_start_train = datetime.now()\n",
     "\n",
     "    history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks=[mc])\n",
     "\n",
     "    dt_end_train = datetime.now()\n",
     "\n",
     "    ''' Predict phrase '''\n",
     "    best_model = cnn_bilstm_att()\n",
     "    best_model.load_weights('./trained_models/' + model_name+ '.hdf5')\n",
     "    best_model.compile(optimizer=adam, loss='categorical_crossentropy',\n",
     "                       metrics=['accuracy', tf.keras.metrics.CategoricalAccuracy(),\n",
     "                                Evaluator.precision, Evaluator.recall, Evaluator.fmeasure])\n",
     "\n",
     "    dt_start_predict = datetime.now()\n",
     "\n",
     "    y_pred = best_model.predict(x_test, batch_size=64)\n",
     "\n",
     "    dt_end_predict = datetime.now()\n",
     "\n",
     "    # Validation curves\n",
     "    Evaluator.plot_validation_curves(model_name, history)\n",
     "    Evaluator.print_validation_report(history)\n",
     "\n",
     "    # Experimental result\n",
     "    Evaluator.calculate_measure(best_model, x_test, y_test)\n",
     "\n",
     "    # Save confusion matrix\n",
     "    Evaluator.plot_confusion_matrix(model_name, y_test, y_pred, title='Confusion matrix', normalize=True)\n",
     "\n",
     "    # Print Training and predicting time\n",
     "    print('Train time: ' + str((dt_end_train - dt_start_train)))\n",
     "    print('Predict time: ' + str((dt_end_predict - dt_start_predict)))\n",
     "\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}