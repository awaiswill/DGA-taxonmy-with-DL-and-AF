
Train on 969072 samples, validate on 107675 samples
Epoch 1/20
968704/969072 [============================>.] - ETA: 0s - loss: 1.0737 - acc: 0.6724 - categorical_accuracy: 0.6724 - precision: 0.7720 - recall: 0.5466 - fmeasure: 0.6207
Epoch 00001: val_loss improved from inf to 0.79290, saving model to ./trained_models/LSTM_ATT_ZAF.hdf5
969072/969072 [==============================] - 115s 118us/sample - loss: 1.0736 - acc: 0.6724 - categorical_accuracy: 0.6724 - precision: 0.7720 - recall: 0.5467 - fmeasure: 0.6208 - val_loss: 0.7929 - val_acc: 0.7659 - val_categorical_accuracy: 0.7659 - val_precision: 0.8777 - val_recall: 0.7008 - val_fmeasure: 0.7793
Epoch 2/20
968704/969072 [============================>.] - ETA: 0s - loss: 0.7308 - acc: 0.7806 - categorical_accuracy: 0.7806 - precision: 0.8831 - recall: 0.7130 - fmeasure: 0.7888
Epoch 00002: val_loss improved from 0.79290 to 0.62295, saving model to ./trained_models/LSTM_ATT_ZAF.hdf5
969072/969072 [==============================] - 113s 116us/sample - loss: 0.7308 - acc: 0.7806 - categorical_accuracy: 0.7806 - precision: 0.8831 - recall: 0.7130 - fmeasure: 0.7888 - val_loss: 0.6230 - val_acc: 0.8127 - val_categorical_accuracy: 0.8127 - val_precision: 0.9031 - val_recall: 0.7403 - val_fmeasure: 0.8135
Epoch 3/20
968704/969072 [============================>.] - ETA: 0s - loss: 0.6085 - acc: 0.8150 - categorical_accuracy: 0.8150 - precision: 0.8895 - recall: 0.7607 - fmeasure: 0.8200
Epoch 00003: val_loss improved from 0.62295 to 0.52933, saving model to ./trained_models/LSTM_ATT_ZAF.hdf5
969072/969072 [==============================] - 113s 117us/sample - loss: 0.6085 - acc: 0.8150 - categorical_accuracy: 0.8150 - precision: 0.8896 - recall: 0.7607 - fmeasure: 0.8200 - val_loss: 0.5293 - val_acc: 0.8384 - val_categorical_accuracy: 0.8384 - val_precision: 0.9129 - val_recall: 0.7731 - val_fmeasure: 0.8371
Epoch 4/20
968704/969072 [============================>.] - ETA: 0s - loss: 0.5367 - acc: 0.8380 - categorical_accuracy: 0.8380 - precision: 0.9011 - recall: 0.7916 - fmeasure: 0.8427
Epoch 00004: val_loss improved from 0.52933 to 0.45625, saving model to ./trained_models/LSTM_ATT_ZAF.hdf5
969072/969072 [==============================] - 113s 117us/sample - loss: 0.5368 - acc: 0.8380 - categorical_accuracy: 0.8380 - precision: 0.9011 - recall: 0.7916 - fmeasure: 0.8427 - val_loss: 0.4563 - val_acc: 0.8636 - val_categorical_accuracy: 0.8636 - val_precision: 0.9192 - val_recall: 0.8245 - val_fmeasure: 0.8693
Epoch 5/20
968704/969072 [============================>.] - ETA: 0s - loss: 0.4801 - acc: 0.8561 - categorical_accuracy: 0.8561 - precision: 0.9107 - recall: 0.8161 - fmeasure: 0.8607
Epoch 00005: val_loss improved from 0.45625 to 0.40855, saving model to ./trained_models/LSTM_ATT_ZAF.hdf5
969072/969072 [==============================] - 113s 117us/sample - loss: 0.4801 - acc: 0.8561 - categorical_accuracy: 0.8561 - precision: 0.9107 - recall: 0.8161 - fmeasure: 0.8607 - val_loss: 0.4086 - val_acc: 0.8764 - val_categorical_accuracy: 0.8764 - val_precision: 0.9241 - val_recall: 0.8420 - val_fmeasure: 0.8811
Epoch 6/20
968704/969072 [============================>.] - ETA: 0s - loss: 0.4339 - acc: 0.8700 - categorical_accuracy: 0.8700 - precision: 0.9176 - recall: 0.8347 - fmeasure: 0.8742
Epoch 00006: val_loss improved from 0.40855 to 0.35389, saving model to ./trained_models/LSTM_ATT_ZAF.hdf5
969072/969072 [==============================] - 114s 117us/sample - loss: 0.4339 - acc: 0.8700 - categorical_accuracy: 0.8700 - precision: 0.9176 - recall: 0.8347 - fmeasure: 0.8742 - val_loss: 0.3539 - val_acc: 0.8960 - val_categorical_accuracy: 0.8960 - val_precision: 0.9367 - val_recall: 0.8644 - val_fmeasure: 0.8991
Epoch 7/20
968704/969072 [============================>.] - ETA: 0s - loss: 0.3957 - acc: 0.8818 - categorical_accuracy: 0.8818 - precision: 0.9230 - recall: 0.8504 - fmeasure: 0.8852
Epoch 00007: val_loss improved from 0.35389 to 0.32139, saving model to ./trained_models/LSTM_ATT_ZAF.hdf5
969072/969072 [==============================] - 113s 117us/sample - loss: 0.3957 - acc: 0.8818 - categorical_accuracy: 0.8818 - precision: 0.9230 - recall: 0.8504 - fmeasure: 0.8852 - val_loss: 0.3214 - val_acc: 0.9041 - val_categorical_accuracy: 0.9041 - val_precision: 0.9396 - val_recall: 0.8776 - val_fmeasure: 0.9075
Epoch 8/20
968704/969072 [============================>.] - ETA: 0s - loss: 0.3658 - acc: 0.8912 - categorical_accuracy: 0.8912 - precision: 0.9279 - recall: 0.8628 - fmeasure: 0.8941
Epoch 00008: val_loss improved from 0.32139 to 0.29170, saving model to ./trained_models/LSTM_ATT_ZAF.hdf5
969072/969072 [==============================] - 114s 118us/sample - loss: 0.3657 - acc: 0.8912 - categorical_accuracy: 0.8912 - precision: 0.9279 - recall: 0.8628 - fmeasure: 0.8941 - val_loss: 0.2917 - val_acc: 0.9148 - val_categorical_accuracy: 0.9148 - val_precision: 0.9438 - val_recall: 0.8926 - val_fmeasure: 0.9175
Epoch 9/20
968704/969072 [============================>.] - ETA: 0s - loss: 0.3425 - acc: 0.8977 - categorical_accuracy: 0.8977 - precision: 0.9308 - recall: 0.8722 - fmeasure: 0.9005
Epoch 00009: val_loss improved from 0.29170 to 0.28479, saving model to ./trained_models/LSTM_ATT_ZAF.hdf5
969072/969072 [==============================] - 113s 117us/sample - loss: 0.3425 - acc: 0.8977 - categorical_accuracy: 0.8977 - precision: 0.9308 - recall: 0.8722 - fmeasure: 0.9005 - val_loss: 0.2848 - val_acc: 0.9150 - val_categorical_accuracy: 0.9150 - val_precision: 0.9417 - val_recall: 0.8945 - val_fmeasure: 0.9175
Epoch 10/20
968704/969072 [============================>.] - ETA: 0s - loss: 0.3215 - acc: 0.9037 - categorical_accuracy: 0.9037 - precision: 0.9332 - recall: 0.8802 - fmeasure: 0.9059
Epoch 00010: val_loss improved from 0.28479 to 0.26402, saving model to ./trained_models/LSTM_ATT_ZAF.hdf5
969072/969072 [==============================] - 113s 117us/sample - loss: 0.3216 - acc: 0.9037 - categorical_accuracy: 0.9037 - precision: 0.9332 - recall: 0.8802 - fmeasure: 0.9059 - val_loss: 0.2640 - val_acc: 0.9214 - val_categorical_accuracy: 0.9214 - val_precision: 0.9440 - val_recall: 0.9027 - val_fmeasure: 0.9229
Epoch 11/20
968704/969072 [============================>.] - ETA: 0s - loss: 0.3028 - acc: 0.9088 - categorical_accuracy: 0.9088 - precision: 0.9353 - recall: 0.8873 - fmeasure: 0.9106
Epoch 00011: val_loss improved from 0.26402 to 0.23936, saving model to ./trained_models/LSTM_ATT_ZAF.hdf5
969072/969072 [==============================] - 114s 117us/sample - loss: 0.3028 - acc: 0.9088 - categorical_accuracy: 0.9088 - precision: 0.9353 - recall: 0.8873 - fmeasure: 0.9106 - val_loss: 0.2394 - val_acc: 0.9293 - val_categorical_accuracy: 0.9293 - val_precision: 0.9477 - val_recall: 0.9149 - val_fmeasure: 0.9310
Epoch 12/20
969072/969072 [==============================] - ETA: 0s - loss: 0.2876 - acc: 0.9133 - categorical_accuracy: 0.9133 - precision: 0.9374 - recall: 0.8937 - fmeasure: 0.9150
Epoch 00012: val_loss improved from 0.23936 to 0.22858, saving model to ./trained_models/LSTM_ATT_ZAF.hdf5
969072/969072 [==============================] - 113s 116us/sample - loss: 0.2876 - acc: 0.9133 - categorical_accuracy: 0.9133 - precision: 0.9374 - recall: 0.8937 - fmeasure: 0.9150 - val_loss: 0.2286 - val_acc: 0.9316 - val_categorical_accuracy: 0.9316 - val_precision: 0.9494 - val_recall: 0.9178 - val_fmeasure: 0.9333
Epoch 13/20
969072/969072 [==============================] - ETA: 0s - loss: 0.2723 - acc: 0.9174 - categorical_accuracy: 0.9174 - precision: 0.9398 - recall: 0.8992 - fmeasure: 0.9190
Epoch 00013: val_loss improved from 0.22858 to 0.21361, saving model to ./trained_models/LSTM_ATT_ZAF.hdf5
969072/969072 [==============================] - 114s 117us/sample - loss: 0.2723 - acc: 0.9174 - categorical_accuracy: 0.9174 - precision: 0.9398 - recall: 0.8992 - fmeasure: 0.9190 - val_loss: 0.2136 - val_acc: 0.9355 - val_categorical_accuracy: 0.9355 - val_precision: 0.9515 - val_recall: 0.9226 - val_fmeasure: 0.9368
Epoch 14/20
968704/969072 [============================>.] - ETA: 0s - loss: 0.2588 - acc: 0.9211 - categorical_accuracy: 0.9211 - precision: 0.9420 - recall: 0.9041 - fmeasure: 0.9227
Epoch 00014: val_loss improved from 0.21361 to 0.20498, saving model to ./trained_models/LSTM_ATT_ZAF.hdf5
969072/969072 [==============================] - 113s 117us/sample - loss: 0.2587 - acc: 0.9212 - categorical_accuracy: 0.9212 - precision: 0.9420 - recall: 0.9041 - fmeasure: 0.9227 - val_loss: 0.2050 - val_acc: 0.9375 - val_categorical_accuracy: 0.9375 - val_precision: 0.9516 - val_recall: 0.9262 - val_fmeasure: 0.9387
Epoch 15/20
968704/969072 [============================>.] - ETA: 0s - loss: 0.2463 - acc: 0.9247 - categorical_accuracy: 0.9247 - precision: 0.9444 - recall: 0.9090 - fmeasure: 0.9263
Epoch 00015: val_loss improved from 0.20498 to 0.19309, saving model to ./trained_models/LSTM_ATT_ZAF.hdf5
969072/969072 [==============================] - 114s 117us/sample - loss: 0.2463 - acc: 0.9247 - categorical_accuracy: 0.9247 - precision: 0.9444 - recall: 0.9090 - fmeasure: 0.9263 - val_loss: 0.1931 - val_acc: 0.9416 - val_categorical_accuracy: 0.9416 - val_precision: 0.9555 - val_recall: 0.9306 - val_fmeasure: 0.9429
Epoch 16/20
968704/969072 [============================>.] - ETA: 0s - loss: 0.2353 - acc: 0.9282 - categorical_accuracy: 0.9282 - precision: 0.9464 - recall: 0.9136 - fmeasure: 0.9297
Epoch 00016: val_loss improved from 0.19309 to 0.18680, saving model to ./trained_models/LSTM_ATT_ZAF.hdf5
969072/969072 [==============================] - 113s 117us/sample - loss: 0.2353 - acc: 0.9282 - categorical_accuracy: 0.9282 - precision: 0.9464 - recall: 0.9136 - fmeasure: 0.9297 - val_loss: 0.1868 - val_acc: 0.9427 - val_categorical_accuracy: 0.9427 - val_precision: 0.9555 - val_recall: 0.9328 - val_fmeasure: 0.9440
Epoch 17/20
968704/969072 [============================>.] - ETA: 0s - loss: 0.2256 - acc: 0.9310 - categorical_accuracy: 0.9310 - precision: 0.9480 - recall: 0.9170 - fmeasure: 0.9323
Epoch 00017: val_loss improved from 0.18680 to 0.17517, saving model to ./trained_models/LSTM_ATT_ZAF.hdf5
969072/969072 [==============================] - 113s 117us/sample - loss: 0.2256 - acc: 0.9310 - categorical_accuracy: 0.9310 - precision: 0.9480 - recall: 0.9170 - fmeasure: 0.9323 - val_loss: 0.1752 - val_acc: 0.9467 - val_categorical_accuracy: 0.9467 - val_precision: 0.9581 - val_recall: 0.9378 - val_fmeasure: 0.9478
Epoch 18/20
968704/969072 [============================>.] - ETA: 0s - loss: 0.2177 - acc: 0.9331 - categorical_accuracy: 0.9331 - precision: 0.9495 - recall: 0.9201 - fmeasure: 0.9345
Epoch 00018: val_loss improved from 0.17517 to 0.17398, saving model to ./trained_models/LSTM_ATT_ZAF.hdf5
969072/969072 [==============================] - 113s 117us/sample - loss: 0.2178 - acc: 0.9331 - categorical_accuracy: 0.9331 - precision: 0.9495 - recall: 0.9201 - fmeasure: 0.9345 - val_loss: 0.1740 - val_acc: 0.9468 - val_categorical_accuracy: 0.9468 - val_precision: 0.9582 - val_recall: 0.9378 - val_fmeasure: 0.9479
Epoch 19/20
968704/969072 [============================>.] - ETA: 0s - loss: 0.2109 - acc: 0.9354 - categorical_accuracy: 0.9354 - precision: 0.9509 - recall: 0.9228 - fmeasure: 0.9366
Epoch 00019: val_loss improved from 0.17398 to 0.16928, saving model to ./trained_models/LSTM_ATT_ZAF.hdf5
969072/969072 [==============================] - 113s 117us/sample - loss: 0.2109 - acc: 0.9354 - categorical_accuracy: 0.9354 - precision: 0.9509 - recall: 0.9228 - fmeasure: 0.9366 - val_loss: 0.1693 - val_acc: 0.9487 - val_categorical_accuracy: 0.9487 - val_precision: 0.9582 - val_recall: 0.9412 - val_fmeasure: 0.9496
Epoch 20/20
968704/969072 [============================>.] - ETA: 0s - loss: 0.2051 - acc: 0.9372 - categorical_accuracy: 0.9372 - precision: 0.9519 - recall: 0.9253 - fmeasure: 0.9384
Epoch 00020: val_loss improved from 0.16928 to 0.16277, saving model to ./trained_models/LSTM_ATT_ZAF.hdf5
969072/969072 [==============================] - 113s 117us/sample - loss: 0.2051 - acc: 0.9372 - categorical_accuracy: 0.9372 - precision: 0.9519 - recall: 0.9253 - fmeasure: 0.9384 - val_loss: 0.1628 - val_acc: 0.9500 - val_categorical_accuracy: 0.9500 - val_precision: 0.9606 - val_recall: 0.9418 - val_fmeasure: 0.9511
dict_keys(['loss', 'acc', 'categorical_accuracy', 'precision', 'recall', 'fmeasure', 'val_loss', 'val_acc', 'val_categorical_accuracy', 'val_precision', 'val_recall', 'val_fmeasure'])

[val_loss] [0.792903458104489, 0.6229503082675504, 0.5293331108944085, 0.45625124152254165, 0.4085547588517557, 0.35389273604744403, 0.32138549870312116, 0.2916981811874395, 0.2847931434470483, 0.26402179284690286, 0.23936414415539625, 0.2285761415039494, 0.21360813038183638, 0.20497976474925816, 0.1930856030069539, 0.18680090499928967, 0.1751677096540479, 0.17398355828171294, 0.16928237104031169, 0.1627689543761536]
[val_acc] [0.7658602, 0.812677, 0.8384026, 0.8635709, 0.8763594, 0.895974, 0.90412813, 0.914762, 0.9150221, 0.9213559, 0.9292872, 0.93156254, 0.9354911, 0.93746924, 0.9415556, 0.94268864, 0.9467286, 0.94681215, 0.9486789, 0.95002556]
[val_categorical_accuracy] [0.7658602, 0.812677, 0.8384026, 0.8635709, 0.8763594, 0.895974, 0.90412813, 0.914762, 0.9150221, 0.9213559, 0.9292872, 0.93156254, 0.9354911, 0.93746924, 0.9415556, 0.94268864, 0.9467286, 0.94681215, 0.9486789, 0.95002556]
[val_precision] [0.87771666, 0.90309, 0.9128753, 0.9192497, 0.9241111, 0.9367373, 0.9396436, 0.94375277, 0.9417277, 0.9439643, 0.9477419, 0.94937265, 0.9515273, 0.95160997, 0.95550025, 0.95552, 0.9580757, 0.95819765, 0.95822245, 0.96055794]
[val_recall] [0.70081335, 0.7402573, 0.77313954, 0.82454664, 0.84203297, 0.8644091, 0.8775977, 0.8926415, 0.89447796, 0.9027154, 0.9149026, 0.9177878, 0.922581, 0.9261899, 0.9306471, 0.9328095, 0.9378164, 0.9377786, 0.94122, 0.9418438]
[val_fmeasure] [0.77925205, 0.8134994, 0.8371467, 0.86927736, 0.88112247, 0.8990872, 0.9075313, 0.9174615, 0.9174711, 0.92285705, 0.93101764, 0.93329847, 0.9368144, 0.9387129, 0.94289863, 0.9440171, 0.94782877, 0.94786686, 0.94963753, 0.95110035]
              precision    recall  f1-score   support

           0     0.9746    0.9871    0.9808    150901
           1     0.9988    0.9999    0.9994    109684
           2     0.9014    0.9895    0.9434     16698
           3     0.9997    0.9997    0.9997     16414
           4     0.7872    0.8885    0.8348     16090
           5     0.6891    0.7902    0.7362      9942
           6     0.8383    0.6434    0.7280      8196
           7     0.8453    0.7376    0.7878      7180
           8     0.9750    0.8978    0.9348      3736
           9     0.8784    0.9446    0.9103      3754
          10     0.5916    0.6033    0.5974      3312
          11     0.8698    0.8257    0.8472      2565
          12     0.9995    0.9980    0.9987      1985
          13     0.9780    0.7752    0.8648      2006
          14     0.5191    0.2184    0.3074      1557
          15     0.4314    0.1001    0.1625      1508
          16     0.6623    0.0984    0.1714      1016
          17     0.6667    0.0026    0.0051       783
          18     0.6057    0.8893    0.7206       596
          19     0.9625    0.9898    0.9760       492
          20     0.5000    0.0140    0.0272       501

    accuracy                         0.9485    358916
   macro avg     0.7940    0.6854    0.6921    358916
weighted avg     0.9455    0.9485    0.9438    358916

precision 0.9454890442806364
recall 0.9485394911344158
F1 0.9438275484982386
precision 0.9485394911344158
recall 0.9485394911344158
F1 0.9485394911344158
